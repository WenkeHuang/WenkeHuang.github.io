
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="description" content="Wenke Huang's homepage">
	<link rel="stylesheet" href="jemdoc.css" type="text/css">
	<title>Wenke Huang (黄文柯)</title>
   <link rel="icon" type="image/png" href="https://www.whu.edu.cn/__local/5/2F/C2/57EDDD9FB0DF712F3AB627163C2_1EF15655_13FCA.png">
</head>

<body>
<div id="layout-content" style="margin-top:25px"></div>

<table>
    <tbody>
    <tr>
    <td width="670">
    <div id="toptitle">
    <h1>Wenke Huang (黄文柯) </h1>
    </div>
    <img style="max-width:30%" alt="Chinese Name photo" src="images/wenke_name_2023.jpg" class="hoverZoomLink">
    <br> Chinese name 👆 written by handsome Dad.
    <h3> Ph.D. Student</h3>
    <p>
    School of Computer Science, Wuhan University<br>
    Email:  <a href="mailto:wenkehuang@whu.edu.cn">wenkehuang@whu.edu.cn</a> <br>
<!--    CV: <a href="/data/wenke_CNCV.pdf">[CN-CV]</a> / <a href="/data/wenke_CV.pdf">[CV]</a> <br>-->
    <a href="https://scholar.google.com/citations?hl=zh-CN&user=aFoCI3MAAAAJ" target="_blank">[Google Scholar]</a>
<!--    <a href="https://blog.csdn.net/qq_41409438?spm=1010.2135.3001.5343">[CSDN]</a>-->
    <a href="https://www.linkedin.com/in/wenkehuang0901/" target="_blank">[LinkedIn]</a>
    <a href="https://github.com/WenkeHuang">[Github]</a>
    </p>
    </td>
    <td>
    </td>
    <td>
    <img src="images/wenke_2024.jpg" border="0" width="150">
    </td>
    </tr></tbody>
</table>

<h2>Short Bio</h2>
<p>
Wenke Huang is a Ph.D. student in <a href="https://cs.whu.edu.cn/"> School of Computer Science at Wuhan University</a>, advised by  <a href="https://marswhu.github.io/">Prof. Mang Ye</a> and <a href="http://sigma.whu.edu.cn/">Prof. Bo Du</a>.
Previously, I received my bachelor degree (Software Engineering and Finance) at <a href="https://www.whu.edu.cn/">Wuhan University</a> in 2021.<br>

I was supported by the Fundamental Research Project for Young Professional from  NSFC (<b>首批</b>国自然博士生基金, <b><a href="https://cs.whu.edu.cn/info/1054/41871.htm">新闻</a></b>),
    the Youth Talents Support Project - Doctoral Student Special Program (<b>首届</b>中国科协青年人才托举工程-博士生专项), and CIE-Tencent Doctoral Research Incentive Project (中国电子学会—腾讯博士生科研激励计划(混元大模型专项)). <br>

    My research focuses on <b>Federated Learning</b> and <b>Multimodal Large Language Models</b>: <b><a href="https://drive.google.com/file/d/1itsc9vfzTWWktQppFHx79PMpYGCYmQIe/view", target="_blank">Romance Never Dies</a></b>
    . <br>

    ✨✨ (<b><font color="red">Hiring</font></b>): We are actively seeking visiting student on above fields ⬆️. Since March 2023, almost everyone who worked with me has published at least <b>Two</b> papers at CCF-A conferences.
    If you are interested,  always feel free to contact me through  <a href="mailto:wenkehuang@whu.edu.cn">Mail</a> or <a href="data/wechat.jpg">Wechat</a>.

<h2>News</h2>
<div style="max-height: 130px; overflow-y: auto; padding: 10px; border-left: 4px solid #2c3e50; margin: 0px 0;">
<style>
  /* 为 Webkit 浏览器（Chrome, Safari, Edge）设置滚动条样式 */
  div::-webkit-scrollbar {
    width: 8px;
  }

  div::-webkit-scrollbar-track {
    background: #e9ecef;
    border-radius: 4px;
  }

  div::-webkit-scrollbar-thumb {
    background: #2c3e50;
    border-radius: 4px;
  }

  div::-webkit-scrollbar-thumb:hover {
    background: #1a252f;
  }

  /* 为 Firefox 设置滚动条样式 */
  div {
    scrollbar-width: thin;
    scrollbar-color: #2c3e50 #e9ecef;
  }
</style>
<ul style="list-style-type: none; padding-left: 0; margin: 0;">
<li>[2025.5] Several papers on MLLM Tuning, Federated Learning are accepted by ICML2025/IJCAI 2025 (<b><font color="red">One Spotlight</font></b>)

<li>[2025.2] Four papers on MLLM Tuning, Federated Learning are accepted by CVPR 2025 (<b><font color="red">Two Oral</font></b>)

<li>[2025.1] One paper about Federated Learning is accepted by ICLR 2025 (<b><font color="red">One Oral</font></b>)

<li>[2024.6] One Survey on Federated Generalization, Robustness, Fairness is accepted by IEEE TPAMI

<li>[2024.5] Two papers are accepted by ICML 2024

<li>[2023.10] One paper is accepted by IEEE TPAMI

<li>[2023.2] One papers is accepted by CVPR 2023

<li>[2022.2] One papers is accepted by CVPR 2022

</li>
</ul>
</div>
<h2>Selected Publications </h2>

†: equal contribution, * : corresponding author

<h3>Survey</h3>
<ul>
    <li>
      Keeping Yourself is Important in Downstream Tuning Multimodal Large Language Model<br>
      <b>Wenke Huang</b>, Jian Liang, Xianda Guo, Yiyang Fang, Guancheng Wan, Xuankun Rong, Chi Wen, <br> Zekun Shi,  Qingyun Li, Didi Zhu, Yanbiao Ma, Ke Liang, Bin Yang, He Li, Jiawei Shao, Mang Ye, Bo Du <br>
      <i>arXiv,  2025</i><br>
        [<a href="https://arxiv.org/abs/2503.04543">Paper</a>][<a href="https://github.com/WenkeHuang/Awesome-MLLM-Tuning">Code</a>]
    </li>
   <li>
      Federated Learning for Generalization, Robustness, Fairness: A Survey and Benchmark<br>
       <b>Wenke Huang</b>, Mang Ye, Zekun Shi, Guancheng Wan, He Li, Bo Du, Qiang Yang <br>
      <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>IEEE TPAMI</b>), <b><font color="red">CCF-A</font></b>, 2024</i><br>
      [<a href="https://arxiv.org/abs/2311.06750">Paper</a>][<a href="https://github.com/WenkeHuang/MarsFL">Code</a>]
   </li>
<!--   <li>-->
<!--      An Empirical Study of Federated Prompt Learning for Vision Language Model<br>-->
<!--       Zhihao Wang,  <b>Wenke Huang<sup>†</sup></b>, Tian Chen, Zekun Shi, Guancheng Wan, Yu Qiao, Bin Yang, Jian Liang, Bing Li, Mang Ye <br>-->
<!--      <i>International Joint Conferences on Artificial Intelligence (<b>IJCAI Survey</b>), <b><font color="red">CCF-A</font></b>, 2025</i><br>-->
<!--        [<a href="">Paper</a>][<a href="">Code</a>]-->
<!--   </li>-->
<!--    <li>-->
<!--      3D Human Interaction Generation: A Survey<br>-->
<!--      Siyuan Fan, <b>Wenke Huang</b>, Xiantao Cai, Bo Du<br>-->
<!--      <i>arXiv,  2025</i><br>-->
<!--        [<a href="https://arxiv.org/abs/2503.13120">Paper</a>][<a href="">Code</a>]-->
<!--    </li>-->
    <li>
      A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations<br>
      Mang Ye, Xuankun Rong, <b>Wenke Huang</b>, Bo Du, Nenghai Yu, Dacheng Tao<br>
      <i>arXiv,  2025</i><br>
        [<a href="https://arxiv.org/abs/2502.14881">Paper</a>][<a href="https://github.com/XuankunRong/Awesome-LVLM-Safety">Code</a>]
    </li>
</ul>


<h3>2025</h3>
<ul>
   <li>
      Kindle Federated Generalization with Domain Specialized and Invariant Knowledge<br>
      <b>Wenke Huang</b>, Mang Ye, Zekun Shi, He Li, Bo Du <br>
      <i>IEEE Transactions on Information Forensics and Security (<b>IEEE TIFS</b>), <b><font color="red">CCF-A</font></b>, 2025</i><br>
      [<a href="https://ieeexplore.ieee.org/document/10919184">Paper</a>][<a href="">Code</a>]
   </li>
   <li>
       Be Confident: Uncovering Overfitting in MLLM Multi-Task Tuning<br>
       <b>Wenke Huang<sup>†</sup></b>,  Jian Liang<sup>†</sup>,  Guancheng Wan, Didi Zhu, He Li, Jiawei Shao, Mang Ye, Bo Du, Dacheng Tao <br>
      <i>International Conference on Machine Learning (<b>ICML</b>), <b><font color="red">CCF-A</font></b>, 2025</i><br>
      [<a href="https://arxiv.org/abs/2411.10928">Paper</a>][<a href="">Code</a>]
   </li>
   <li>
      Learn from Downstream and Be Yourself in Multimodal Large Language Model Fine-Tuning<br>
       <b>Wenke Huang<sup>†</sup></b>,  Jian Liang<sup>†</sup>, Zekun Shi, Didi Zhu, Guancheng Wan, He Li, Bo Du, Dacheng Tao, Mang Ye <br>
      <i>International Conference on Machine Learning (<b>ICML</b>), <b><font color="red">CCF-A</font></b>, 2025</i><br>
      [<a href="https://arxiv.org/abs/2411.10928">Paper</a>][<a href="">Code</a>]
   </li>
   <li>
      LoRASculpt: Sculpting LoRA for Harmonizing General and Specialized Knowledge in Multimodal Large Language Models<br>
       Jian Liang, <b>Wenke Huang<sup>†</sup></b>, Guancheng Wan, Qu Yang, Mang Ye <br>
      <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>),  <b><font color="#9400D3">Oral (Top 3.3%)</font></b>, <b><font color="red">CCF-A</font></b>, 2025 </i> <br>
      [<a href="https://arxiv.org/abs/2503.16843">Paper</a>][<a href="">Code</a>]
   </li>
<!--    <li>
      EMOE: Modality-Specific Enhanced Dynamic Emotion Experts<br>
       Yiyang Fang, <b>Wenke Huang<sup>†</sup></b>, Guancheng Wan, Kehua Su, Mang Ye <br>
      <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), <b><font color="red">CCF-A</font></b>, 2025 </i> <br>
      [<a href="">Paper</a>][<a href="">Code</a>]
   </li> -->
<!--   <li>-->
<!--      Pixel-wise Divide and Conquer for Federated Vessel Segmentation<br>-->
<!--       Tian Chen, <b>Wenke Huang<sup>†</sup></b>, Zhihao Wang, Zekun Shi, He Li, Wenhui Dong, Mang Ye, Bo Du, Yongchao Xu <br>-->
<!--      <i>International Joint Conferences on Artificial Intelligence (<b>IJCAI</b>), <b><font color="red">CCF-A</font></b>, 2025</i><br>-->
<!--        [<a href="">Paper</a>][<a href="">Code</a>]-->
<!--   </li>-->
   <li>
      Geometric Knowledge-Guided Localized Global Distribution Alignment for Federated Learning<br>
       Yanbiao Ma, Wei Dai, <b>Wenke Huang<sup>*</sup></b>, Jiayi Chen <br>
      <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>),  <b><font color="#9400D3">Oral (Top 3.3%)</font></b>, <b><font color="red">CCF-A</font></b>, 2025 </i> <br>
      [<a href="https://arxiv.org/pdf/2503.06457">Paper</a>][<a href="https://github.com/WeiDai-David/2025CVPR_GGEUR">Code</a>]
   </li>
<!--   <li>-->
<!--      FedSPA: Generalizable Federated Graph Learning under Homophily Heterogeneity<br>-->
<!--       Zihan Tan, Guancheng Wan, <b>Wenke Huang<sup>†</sup></b>, Guibin Zhang, He Li, Carl Yang, Mang Ye <br>-->
<!--      <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), <b><font color="red">CCF-A</font></b>, 2025 </i> <br>-->
<!--      [<a href="https://www.cs.emory.edu/~jyang71/files/fedspa.pdf">Paper</a>][<a href="">Code</a>]-->
<!--   </li>-->
   <li>
      Energy-based Backdoor Defense Against Federated Graph Learning<br>
       Guancheng Wan, Zitong Shi, <b>Wenke Huang<sup>†</sup></b>, Guibin Zhang, Dacheng Tao, Mang Ye <br>
      <i>International Conference on Learning Representations (<b>ICLR</b>), <b><font color="#9400D3">Oral (Top 1.8%)</font></b>, 2025 </i> <br>
      [<a href="https://openreview.net/forum?id=5Jc7r5aqHJ">Paper</a>][<a href="">Code</a>]
   </li>
   <li>
      Catch Your Emotion: Sharpening Emotion Perception in Multimodal Large Language Models<br>
       Yiyang Fang, Jian Liang,  <b>Wenke Huang<sup>†</sup></b>, He Li, Kehua Su, Mang Ye <br>
      <i>International Conference on Machine Learning (<b>ICML</b>), <b><font color="#9400D3">Spotlight (Top 2.6%)</font></b>, <b><font color="red">CCF-A</font></b>, 2025</i><br>
      [<a href="">Paper</a>][<a href="">Code</a>]
   </li>
</ul>

<h3>2024</h3>
<ul>
<!--   <li>
      Parameter Disparities Dissection for Backdoor Defense in Heterogeneous Federated Learning<br>
       <b>Wenke Huang</b>, Mang Ye, Zekun Shi, Guancheng Wan, He Li, Bo Du <br>
       <i>Conference on Neural Information Processing System (<b>NeurIPS</b>), <b><font color="red">CCF-A</font></b>, 2024</i><br>
      [<a href="">Paper</a>][<a href="https://github.com/WenkeHuang/FDCR">Code</a>]
   </li> -->
  <li>
      Self-Driven Entropy Aggregation for Byzantine-Robust Heterogeneous Federated Learning<br>
       <b>Wenke Huang<sup>†</sup></b>, Zekun Shi<sup>†</sup>, Mang Ye, He Li, Bo Du <br>
      <i>International Conference on Machine Learning (<b>ICML</b>), <b><font color="red">CCF-A</font></b>, 2024</i><br>
      [<a href="https://openreview.net/forum?id=k2axqNsVVO">Paper</a>][<a href="https://github.com/WenkeHuang/SDEA">Code</a>]
   </li>
<!--    <li>
      Federated Learning with Long-Tailed Data via Representation Unification and Classifier Rectification<br>
       <b>Wenke Huang<sup>†</sup></b>, Yuxia Liu<sup>†</sup>, Mang Ye, Jun Chen, Bo Du <br>
      <i>IEEE Transactions on Information Forensics and Security (<b>IEEE TIFS</b>), <b><font color="red">CCF-A</font></b>, 2024</i><br>
      [<a href="https://ieeexplore.ieee.org/document/10534053">Paper</a>][<a href="https://github.com/liuyuxia211/RUCR">Code</a>]
   </li> -->
<!--    <li>
      Self Knowledge Distillation with Dimensional History Knowledge<br>
       <b>Wenke Huang</b>, Mang Ye, Zekun Shi, He Li, Bo Du <br>
      <i>SCIENCE CHINA Information Sciences (<b>SCIS</b>), <b><font color="red">CCF-A</font></b>, 2024</i><br>
      [<a href="">Paper</a>][<a href="">Code</a>]
   </li> -->
   <li>
      Fisher Calibration for Backdoor-Robust Heterogeneous Federated Learning<br>
      <b>Wenke Huang</b>,  Mang Ye, Zekun Shi, Bo Du, Dacheng Tao  <br>
      <i>European Conference on Computer Vision (<b>ECCV</b>), <b><font color="#4169e1">CCF-B</font></b>, 2024</i><br>
      [<a href="">Paper</a>][<a href="">Code</a>]
   </li>
<!--    <li>
      Revisiting Federated Learning with Label Skew: An Over-Confidence Perspective<br>
       Mang Ye<sup>†</sup>, <b>Wenke Huang<sup>†</sup></b>, Zekun Shi, He Li, Bo Du  <br>
      <i>SCIENCE CHINA Information Sciences (<b>SCIS</b>), <b><font color="red">CCF-A</font></b>, 2024</i><br>
      [<a href="https://www.sciengine.com/SCIS/doi/10.1007/s11432-023-4202-1">Paper</a>][<a href="https://github.com/WenkeHuang/RevisitFL">Code</a>]
   </li> -->
<!--   <li>-->
<!--      Fair Federated Learning under Domain Skew with Local Consistency and Domain Diversity<br>-->
<!--       Yuhang Chen<sup>†</sup>, <b>Wenke Huang<sup>†</sup></b>, Mang Ye  <br>-->
<!--      <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), <b><font color="red">CCF-A</font></b>, 2024</i><br>-->
<!--        [<a href="https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Fair_Federated_Learning_under_Domain_Skew_with_Local_Consistency_and_CVPR_2024_paper.html">Paper</a>][<a href="https://github.com/yuhangchen0/FedHEAL">Code</a>]-->
<!--   </li>-->
<!--   <li>-->
<!--      Label-Free Backdoor Attacks in Vertical Federated Learning: An Embedding Gradient-Guided Approach with Selectively Sample Switching<br>-->
<!--       Wei Shen<sup>†</sup>, <b>Wenke Huang<sup>†</sup></b>, Guancheng Wan, Mang Ye  <br>-->
<!--    <i>Association for the Advancement of Artificial Intelligence (<b>AAAI</b>), <b><font color="red">CCF-A</font></b>, 2025</i><br>-->
<!--        [<a href="">Paper</a>][<a href="">Code</a>]-->
<!--   </li>-->
<!--   <li>-->
<!--      FedSSP: Federated Graph Learning with Spectral Knowledge and Personalized Preference<br>-->
<!--       Zihan Tan<sup>†</sup>, Guancheng Wan<sup>†</sup>, <b>Wenke Huang<sup>†</sup></b>, Mang Ye  <br>-->
<!--       <i>Conference on Neural Information Processing System (<b>NeurIPS</b>), <b><font color="red">CCF-A</font></b>, 2024</i><br>-->
<!--      [<a href="">Paper</a>][<a href="">Code</a>]-->
<!--   </li>-->
<!--   <li>-->
<!--      Federated Recommendation with Explicitly Encoding Item Bias<br>-->
<!--       Zhihao Wang<sup>†</sup>, He Bai<sup>†</sup>, <b>Wenke Huang<sup>†</sup></b>, Duantengchuan Li, Jian Wang, Bing Li  <br>-->
<!--    <i>Association for the Advancement of Artificial Intelligence (<b>AAAI</b>), <b><font color="red">CCF-A</font></b>, 2025</i><br>-->
<!--        [<a href="">Paper</a>][<a href="">Code</a>]-->
<!--   </li>-->
<!--   <li>-->
<!--      FedAS: Bridging Inconsistency in Personalized Federated Learning<br>-->
<!--       Xiyuan Yang, <b>Wenke Huang</b>, Mang Ye  <br>-->
<!--      <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), <b><font color="red">CCF-A</font></b>, 2024</i><br>-->
<!--        [<a href="https://openaccess.thecvf.com/content/CVPR2024/html/Yang_FedAS_Bridging_Inconsistency_in_Personalized_Federated_Learning_CVPR_2024_paper.html">Paper</a>][<a href="https://github.com/xiyuanyang45/FedAS">Code</a>]-->
<!--   </li>-->
<!--    <li>-->
<!--    Federated Graph Learning under Domain Shift with Generalizable Prototypes<br>-->
<!--    Guancheng Wan, <b>Wenke Huang</b>, Mang Ye  <br>-->
<!--    <i>Association for the Advancement of Artificial Intelligence (<b>AAAI</b>), <b><font color="red">CCF-A</font></b>, 2024</i><br>-->
<!--    [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/29468">Paper</a>][<a href="https://github.com/GuanchengWan/FGGP">Code</a>]-->
<!--    </li>-->
<!--   <li>-->
<!--      Resisting Over-Smoothing in Graph Neural Networks via Dual-Dimensional Decoupling<br>-->
<!--       Wei Shen, Mang Ye, <b>Wenke Huang</b><br>-->
<!--      <i>ACM Multimedia (<b>ACM MM</b>), <b><font color="red">CCF-A</font></b>, 2024</i><br>-->
<!--        [<a href="https://dl.acm.org/doi/10.1145/3664647.3681204">Paper</a>][<a href="https://github.com/shentt67/DDCD">Code</a>]-->
<!--   </li>-->
<!--   <li>-->
<!--      S3GCL: Spectral, Swift, Spatial Graph ContrastiveLearning<br>-->
<!--       Guancheng Wan, Yijun Tian, <b>Wenke Huang</b>, Nitesh v chawla, Mang Ye  <br>-->
<!--      <i>International Conference on Machine Learning (<b>ICML</b>), <b><font color="red">CCF-A</font></b>, 2024</i><br>-->
<!--        [<a href="https://openreview.net/forum?id=znKAWRZSF9">Paper</a>][<a href="https://github.com/GuanchengWan/S3GCL">Code</a>]-->
<!--   </li>-->
<!--  <li>-->
<!--      Label-Aware Calibration and Relation-Preserving in Visual Intention Understanding<br>-->
<!--       QinHongYa Shi, Mang Ye, <b>Wenke Huang</b>, Weijian Ruan, Bo Du <br>-->
<!--      <i>IEEE Transactions on Image Processing (<b>IEEE TIP</b>), <b><font color="red">CCF-A</font></b>, 2024</i><br>-->
<!--        [<a href="https://ieeexplore.ieee.org/document/10482852/">Paper</a>][<a href="https://github.com/ShiQingHongYa/LabCR">Code</a>]-->
<!--   </li>-->
</ul>

<h3>2023</h3>
<ul>
   <li>
      Generalizable Heterogeneous Federated Cross-Correlation and Instance Similarity Learning<br>
       <b>Wenke Huang</b>, Mang Ye, Zekun Shi, Bo Du<br>
      <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>IEEE TPAMI</b>), <b><font color="red">CCF-A</font></b>, 2023</i><br>
        [<a href="https://ieeexplore.ieee.org/document/10295990">Paper</a>][<a href="https://github.com/WenkeHuang/FCCL">Code</a>]
   </li>
   <li>
      Rethinking Federated Learning with Domain Shift: A Prototype View<br>
       <b>Wenke Huang</b>, Mang Ye, Zekun Shi, He Li, Bo Du<br>
      <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), <b><font color="red">CCF-A</font></b>, 2023</i><br>
        [<a href="https://ieeexplore.ieee.org/document/10203389/">Paper</a>][<a href="https://github.com/WenkeHuang/RethinkFL">Code</a>]
   </li>
   <li>
      Federated Graph Semantic and Structural Learning<br>
       <b>Wenke Huang<sup>†</sup></b>, Guancheng Wan<sup>†</sup>, Mang Ye, Bo Du<br>
      <i>International Joint Conferences on Artificial Intelligence (<b>IJCAI</b>), <b><font color="red">CCF-A</font></b>, 2023</i><br>
        [<a href="https://www.ijcai.org/proceedings/2023/426">Paper</a>][<a href="https://github.com/wgc-research/fgssl">Code</a>]
   </li>
<!--      <li>-->
<!--      Dynamic Personalized Federated Learning with Adaptive Differential Privacy<br>-->
<!--        Xiyuan Yang<sup>†</sup>, <b>Wenke Huang<b>†</b></b>, Mang Ye <br>-->
<!--       <i>Conference on Neural Information Processing System (<b>NeurIPS</b>), <b><font color="red">CCF-A</font></b>, 2023</i><br>-->
<!--        [<a href="https://papers.nips.cc/paper_files/paper/2023/file/e4724af0e2a0d52ce5a0a4e084b87f59-Paper-Conference.pdf">Paper</a>][<a href="https://github.com/xiyuanyang45/DynamicPFL">Code</a>]-->
<!--   </li>-->
</ul>

<h3>2022</h3>
<ul>
   <li>
      Few-Shot Model Agnostic Federated Learning <br>
              <b>Wenke Huang</b>, Mang Ye, Bo Du, Xiang Gao<br>
      <i>ACM Multimedia (<b>ACM MM</b>), <b><font color="red">CCF-A</font></b>, 2022</i><br>
        [<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548764">Paper</a>][<a href="https://github.com/FangXiuwen/FSMAFL">Code</a>]
   </li>
   <li>
      Learn from Others and Be Yourself in Heterogeneous Federated Learning<br>
              <b>Wenke Huang</b>, Mang Ye, Bo Du<br>
      <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), <b><font color="red">CCF-A</font></b>, 2022 </i> <br>
        [<a href="https://ieeexplore.ieee.org/document/9879190/">Paper</a>][<a href="https://github.com/WenkeHuang/FCCL">Code</a>]
   </li>
</ul>

<h2>Selected Awards and Honors</h2>
<ul>
<li>Youth Talents Support Project - Doctoral Student Special Program, 2025 January <br>
    (<b><font color="red">主持</font></b>首届中国科协青年人才托举工程-博士生专项)
</li>
<li>Fundamental Research Project for Young Professional from NSFC, 2024 April <br>
    (<b><font color="red">主持</font></b>首届国家自然科学基金青年学生基础研究项目（博士研究生), <b><a href="https://cs.whu.edu.cn/info/1054/41871.htm">Link</a></b>)
</li>
<li>Top 10 Academic Stars of the 18th Wuhan University Graduate Students, 2024 December <br>
    (武汉大学第十八届研究生“十大学术之星”, <b><font  color="red">Top 0.1‰ in Wuhan University</font></b>, <b><a href="https://mp.weixin.qq.com/s/N5Jh1s-P7kmZF1Es8kyFaQ">Link</a></b>)
</li>
<li>Lei Jun Excellence Scholarship, 2024 November <br>
    (雷军卓越奖学金, <b>全校10人</b>, <b><font  color="red">Top 0.1‰ in Wuhan University</font></b>, <b><a href="https://mp.weixin.qq.com/s/EyUdkcVaDL7CcZORf3ruJg">Link</a></b>)
</li>
<!--<li>The second "Pioneer of Computer Science" student, 2024 April <br>-->
<!--    (第二届计科先锋年度人物, <b>10 students in the School of Computer Science, Wuhan University</b>, <b><a href="https://mp.weixin.qq.com/s/zdx8hH8-g0FScgZvkYQRnw">Link</a></b>)-->
<!--</li>-->
<!--<li>Second Prize of 1th China's Innovation Challenge on Artificial Intelligence Application Scene, 2023 Dec <br>-->
<!--  (全国人工智能应用场景创新挑战赛全国二等奖)-->
<!--</li>-->
<!--<li>Graduate Academic Innovation First Prize, 2023 Oct <br>-->
<!--    (研究生学术创新一等奖, <b><font color="red">Top 1% in Wuhan University</font></b>)-->
<!--</li>-->
<!--<li>Lei Jun Computer Graduate Scholarship, 2023 Oct <br>-->
<!--  (雷军计算机研究生奖学金, <b>11 PhD students in the School of Computer Science, Wuhan University</b>)-->
<!--</li>-->
<!--<li>The 5th China Graduate Artificial Intelligence Innovation Competition National Third Prize, 2023 Sep <br>-->
<!--(第五届中国研究生人工智能创新大賽全国三等奖)-->
<!--</li>-->
<!--<li>Guotai Junan First Class Scholarship, 2022 Nov <br>-->
<!--  (国泰君安一等奖, <b>2 PhD students in the School of Computer Science, Wuhan University</b>)-->
<!--</li>-->
<li>Meritorious Winner in the MCM/ICM, 2020 Feb <br>
(美国大学生数学建模竞赛 Meritorious 奖, <b><a href="data/Meritorious_2020.pdf">Link</a></b>)
</li>
<li>National Second Prize in the 9rd CHINA SOFTWARE CUP, 2020 Aug <br>
(第九届“中国软件杯”大赛全国二等奖, <b><a href="https://www.bilibili.com/video/BV17z4y1D7JF?share_source=copy_web">Link</a></b>)
</li>
<li>Futures Practitioner Qualification Certificate, 2019 Nov <br>
(CFA 期货从业人员资格证, <b><a href="data/CFA_CHINA.jpg">Link</a></b>)
</li>
<li>National Third Prize in the 8rd CHINA SOFTWARE CUP, 2019 Sep <br>
(第八届“中国软件杯”大赛全国三等奖, <b><a href="https://www.bilibili.com/video/BV1Gz4y1X7SG/?share_source=copy_web&vd_source=7f084fcec3ce6eb92dd84625b03c42d1">Link</a></b>)
</li>
</ul>



<h2>Academic Service</h2>
<table>
<tbody><tr>
<td style="width:20px">
</td>
<td valign="middle">
  <div>
  - Reviewer for CVPR, NeurIPS, ICML, ICCV, ICLR, AAAI, IJCAI, ACMMM, AISTATS, ECCV, ...<br><br>
  - Reviewer for IEEE-(TIFS, TKDE, TPDS, TNNLS, TNET, TMI, TIM, TCSVT), ACM-(CSUR, TKDD), Scientific Reports, Neural Networks, ... <br><br>
  - <b><font color="red">Outstanding Reviewer</font></b>, CVPR, 2025
<!--  <li>-->
<!--   <b><font color="red">Outstanding Reviewer</font></b>, CVPR, 2021-->
<!--   </li><br><br>-->
  </div>
</td>
</tr></tbody>
</table>
<ul>
<li>VALSE 2025-学生论坛, 2025 June,  <b><a href="https://mp.weixin.qq.com/s/E9PyUWEiNNuQ9MmCPmYfMw">Link</a></b>
<li>可信联邦学习冬令营-学生分享, 2024 Nov,  <b><a href="https://mp.weixin.qq.com/s/bhYOqDuxAfyqRhw3tu9jLw">Link</a></b>
<li>第七届中国模式识别与计算机视觉大会-博士生论坛, 2024 Oct,  <b><a href="https://mp.weixin.qq.com/s/9yi9SesOJ9hTGSJzwc5D4A">Link</a></b>
<li>武汉计算机软件工程学会-学术交流活动, 2024 Sep,  <b><a href="https://mp.weixin.qq.com/s/hgUY0a2PVNWehx_MAXLksA">Link</a></b>
<li>中国图象图形学学会-第四期学生会员分享论坛, 2023 June,  <b><a href="https://mp.weixin.qq.com/s/1NdcjW0HxwMpPpSMOsSWhQ">Link</a></b>
</li>
</ul>

<h2>Misc </h2>
<ul>
<li>
<details>
<summary>Reading Note</summary>
<p>06/2025  如果你尝试用一幅图来描绘人们的幸福/效用背后的所有影响因素，并预测人们的选择，那注定无法成功，因为如此多的因素注定无法用一幅图画来描绘。不论用期望效用理论还是用前景理论来描绘都是如此。然而，两种理论都捕捉到了一些人们的幸福和选择背后的重要因素。 --《行为金融学通识》</p>
<p>05/2025  一旦到了寒山，烦恼都结束--不再纠结，不再忐忑。我闲散地在崖壁上涂写诗句，接受到来的一切，像一叶不系之舟。 --《砌石与寒山诗》</p>
<p>04/2025  如果你志在追求艺术追求文学，那么去读一读希腊人写的东西好了。因为要诞生真正的艺术，奴隶制度是必不可少的。而古希腊人便是这样：奴隶们耕种，烧饭，划船，而市民们则可以在地中海的阳光下陶醉于吟诗作赋，埋头于数学解析。所谓艺术便是这么一种东西。 --《且听风吟》</p>
<p>03/2025   因为正如赫鲁晓夫所说，一旦互相发射导弹，共产主义的灰烬和资本主义的灰烬将没有什么差别，连最极端的意识形态倡导者也分辨不出来，因为他也已经死了。
    在当今这个时代，面对如此多的不确定性，只有一点是确定的：我们要面对“世界是不确定的”这个事实。 -- 《不确定的时代》</p>
<p>12/2024    也许艺术家的目光和心思已在别处。也许他们已经感到需要妥协。成为一名艺术企业家的后果之一是，你会像任何从商的人一样，容易接受权宜的哲学，接受偶尔也要与魔鬼做交易的现实。一旦你与那个尖尾巴的魔鬼从同一把勺子里喝水，
不虚伪就变得极其困难。比如你前一天晚上刚参加过一个时髦的博物馆晚宴，刚好坐在某个投资银行行长的旁边，而他恰巧又是你作品的主要收藏者或客户之一，那你如何创作楚深刻的、发自内心的反资本主义的艺术品呢？再者，当你自己的碳排放量大远大于大部分人时，
你怎么创作出有关环境的作品？你是否能错做出旨在揭露社会不公的绘画和雕塑作品，而你又明显从这个社会中受益？还有，你是否会批判一个你作为核心成员的机构？答案是，你不会。-- 《现代艺术150年》</p>
<p>11/2024    在寸土寸金的江湖里面我参悟人性，桀骜不驯的侠客按照自己的蓝图登顶。 -- 《龙Loong》</p>
<p>10/2024 在这里，我们终于回到我们的出发点。实际上根本没有艺术这回事，只有艺术家，他们是些男男女女，具有惊人的天赋，善于平衡形状和色彩以达到“合适”的效果。
更稀罕的是具有正直性格的人，他们不肯在半途止步，时刻准备放弃所有唾手可得的效果，放弃所有表面上的成功，去踏踏实实地经历工作中的辛劳和痛苦。我们相信永远都会有艺术家诞生。
但是会不会也有艺术？这在同样大的程度上也有赖于我们自己，也就是艺术家的公众。通过我们的冷漠或我们的关心，通过我们的成见或我们的理解，我们还是可以决定事情的结局。
恰恰是我们自己，必须保证传统的命脉不致中断，保证艺术家仍然有机会去丰富那串宝贵的珍珠，那是往昔留给我们的传家之宝。 -- 《艺术的故事》</p>
<p>09/2024 用尽全力飞翔吧，这样当你老了之后在僧庐下听雨的时候，你才有那些走马般的瞬间在脑海中流过，你不会后悔的。你曾经满世界地远行，你要去一个地方，你从未去过，不知道是哪里，但你相信那里很美。 -- 《龙与少年游》</p>
<p>08/2024 在现实世界中，存在着一颗北极星，那是小熊星座中最明亮的恒星。而在思想的世界里，却存在无数个类似的导航指引。每一种新的追求，每一个新的痴迷，都悬挂在黑暗的地平线上，闪烁着耀眼的光芒，向不懈追寻的人们招手致意。这就是为什么我最大的快乐在于知道旅程永远不会结束，我也永远不会停歇。总会有新的事物等着我去追逐探索。对科学家而言，想象力就如同布满北极星的璀璨天空。 -- 《我看见的世界 李飞飞自传》</p>
<p>07/2024 “猎人”和“农夫”之间的关键区别是,“猎人”知道自己想要完成什么，想解决什么问题，想使用什么方法。“猎人”是前瞻主动的。相反，“农夫”被动做出回应，他们的动力来自其他人的工作，他们修正这些工作中的错误或是加以扩展。又或者他们会参加朋友的一些不相关项目，通过这种方式获得发表机会。有时这种区别并不明显，比如，与同事的一次交谈，或对篇重要论文的回应，兴许为他们带来了终生投入的工作。尽管如此，但我认为这就是学者在思考自己研究时的重要区别。 -- 《普林斯顿经济学研究指南》</p>
<p>06/2024 “远离我的欲望”，这是珍妮 霍尔泽在时代广场大屏幕上写下的句子。接下来，人们会读到这样的句子：“过多的欲望是不道德的，滥用权力从来都不是什么新鲜事。’作者认为这些句子都是一些老生常谈的道理，都是人们聊天时经常会说到的。这些有着言外之意的句子，在人流涌动的大都市中慢慢地影响着人们。 -- 《艺术流派鉴赏方法》</p>
<p>05/2024 为了掩盖自己的真实意图，银行家们在讨论中央银行形式时，决定采取地区性储备中心的形式，用“区域性”和“分散性”这个虚假的面纱，向社会表明这似乎是独立的区域中央银行，以掩盖他们青睐并实施
欧洲式中央银行的意图。看上去储备和纸钞的发型“好像是“分散到地区储备银行手中，但事实上”却集中到中央管制委员会手中，并由他们进行协调。 -- 《美联储的起源》</p>
<p>04/2024 但是,尽管这么说，我却觉得我这一生并不空虚；我活得很充实，也很有意思，因为有我们仨。也可说：我们仨都没有虚度此生，因为是我们仨。 -- 《我们仨》</p>
<p>03/2024 我一直认为，在科学研究这一领域，乐观对成功而言同样不可或缺；我遇到的成功的科学家都会夸大他或她正在进行的研究的重要性。我还相信，不爱夸大自己重要性的人在反复面对挫折和失败时会一蹶不振，这种情况也是大多数研究人员的结局。 -- 《思考，快与慢》</p>
<p>02/2024 或许最奇怪的是，库珀、迪米特洛夫和劳发现一些公司的核心业务与互联网无关，却决定更改名字来包含“com”，此类公司在公告宣布的5天之内产生23%的异常汇回报，甚至在将事件窗口扩大至之后60天能观察到140%的异常汇报。这是一个在工作中应用代表性启发的好例子。由此可见，市场能够有效处理的信息就这么点儿。 -- 《行为金融学》</p>
<p>01/2024 奢侈不在于你买得起多少钱的东西。奢侈是中间是，是如何恰如其分地对待它，是要花时间去理解体会它，然后选出好的。奢侈就是买正确的东西。 -- 《奢侈的》</p>
<p>12/2023 如果你想投机的话，请睁大自己的双眼，知道最终有可能亏本；请确保将风险额度控制在一定范围内，并将投机与你的投资计划完全分开。 -- 《聪明的投机者》</p>
<p>11/2023 做某事是为了其他事情，做其他事情又是为了另一些事情，等等。当我们“他律”地行动是，我们就是为了某些外在与我们所给定的目的而行动的，我们是自己所追求的各种目的的工具，而非目的的的设定者。
康德的意志自由观念与此截然对立。当我们自律地行动——根据我们给自己所立的法则行动——时，我们做某事是为了这件事本身，它自己就是目的。我们不再是外在于我们所给定的各种目的的工具。 -- 《公正：何谓正当之为？》</p>
<p>10/2023 制度改革必须不断适应新的情况和挑战。理解和评价改革，不能生搬硬套某种抽象的哲学或理论标准，而必须深入了解改革背景和约束条件，仔细考量在特定时空下所产生的改革效果。 -- 《置身事内：中国政府与经济发展》</p>
<p>09/2023 而你们送给我的礼物，却能和我朝夕相处，至死方休；我甚至还能将它遗爱人间而含笑而终。 -- 《查令十字街84号》</p>
<p>08/2023 事实上，当哲学家对“杀人”和“任人死去“的区别感兴趣时，他们常常将自己置于代理人的视角。 -- 《伦理学反教材》</p>
<p>07/2023 愿为江水，与君重逢。 -- 《命运 文在寅自传》</p>
<p>06/2023 想知道人生如何得到幸福，首先研究怎么样才能变得痛苦；想知道企业如何能够做强做大，先了解企业怎么才能走向衰败；想知道如何在股市投资成功，先了解怎样会导致亏损。躲开越多导致失败的因素，获取成功的概率就越大。能躲开所有导致
失败的因素，想不成功那纯属做梦。 -- 《巴芒演义》</p>
<p>05/2023 “如果没有我，巴黎时装周就没什么看头。我山本耀司本人就要做‘反耀司’风格。”就像这样，我一直不断给自己施压。 -- 《做衣服》</p>
<p>04/2023 只是将卫生纸中间的芯改成四角形，就发生了如此巨大的变化。我之所以强调这个提案的意义，并不是要将世界上的卷筒卫生纸都改成四角形，而是希望大家能够注意到“四角形卷筒卫生纸”所代表的“批判性”。单单从生活的立场来看，设计也具有一种批判性。
设计的这种属性由来已久。若我们去追溯设计概念的缘起、设计行为的发生，就会发生设计本身就具有批判性。如果大家能够从圆形卷筒的卫生纸与四角形卷筒的卫生纸之间的差异中感受到这种批判性的存在，是我和设计师共同的荣幸。 -- 《设计中的设计》</p>
<p>03/2023 为那一天而活的意义在于，没办法为那一天而活。好，我要出发。时间已到。 -- 《山本耀司：我投下一枚炸弹》</p>
<p>02/2023 不管全世界所有人怎么说，我都认为自己的感受才是正确的。无论别人怎么看，我绝不打乱自己的节奏。喜欢的事自然可以坚持，不喜欢怎么也长久不了。 -- 《当我谈跑步时我谈些什么》</p>
<p>01/2023 每个人心里都有个死小孩。 -- 《龙族》</p>
      </details>
    </li>
<li>
I am a big fans of CBlock, Higher Brother, GOSH, and Zhanfei Lan.
</li>
<li>
I enjoy fitness, hiking, swimming, skateboarding, and road cycling.
</li>
<li>
To see the world, things dangerous to come to, to see behind walls, to draw closer, to find each other and to feel. That is the purpose of LIFE.
</li>
<li>
你要這麼想，凡事他都有兩面性，一面是好的，另一面是更好的
</li>
<li>
纯真而不欠闻达，善良而不失坚强，把生命高举在尘埃之上，又融化于社会之中，这应当是我们这一代的共同追求
</li>
</ul>

<a href="https://www.easycounter.com/">
<img src="https://www.easycounter.com/counter.php?wenkehuang"
border="0" alt="Website Hit Counters"></a>

<div id="footer">
	<div id="footer-text"></div>
</div>
Last update: 06/2025 by Wenke Huang.
</body>
</html>

